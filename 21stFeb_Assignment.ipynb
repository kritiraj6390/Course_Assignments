{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3e95ff2-d87d-43e0-bc84-48846791c2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "424b14ec-0bc9-4350-9063-0ee298ea0e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans: Web scrapping is the process of extracting data from the web automatically using a code. \n",
    "# Some of the main use cases of web scraping include price monitoring, price intelligence, news monitoring, lead generation, and market research among many others.\n",
    "\n",
    "# The areas of businesses where web scrapping is used are as follows:\n",
    "# a. A web scraping software can be used to generate leads for marketing. Email and Phone lists for cold outreach can be built by scraping the data from relevant websites.\n",
    "# b. Property details displayed by real estate websites like 9acres can be extracted using a Web Scraping software. \n",
    "# c. Scrape hotel/restaurant ratings and reviews from websites like TripAdvisor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e16e00fe-da38-4273-aea7-d3cadb207a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99b653f6-fbac-4512-9faf-4c857e99bb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual Web Scraping: \n",
    "# Web Scraping Libraries: Web scraping libraries such as BeautifulSoup, Scrapy, and PyQuery \n",
    "# Browser Extensions: Browser extensions such as Data Miner and Web Scraper \n",
    "# Headless Browsers: Headless browsers such as PhantomJS and Selenium can be used for web scraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dd31f70-f9e7-4595-b360-8517bf1bb9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4bda663-946e-4561-bc84-e310e0c374ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beautiful Soup is a Python library that is used for web scraping purposes. It provides a simple way to parse HTML and XML documents and extract data from them. Beautiful Soup helps developers navigate and search through the structure of an HTML or XML document using Python code.\n",
    "# Beautiful Soup is widely used for web scraping because it is easy to use, efficient, and provides a range of features for parsing and extracting data from HTML and XML documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa7c7236-0e2d-41d9-8348-7e453121e7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d6c6173-f931-46c8-a5ff-49f3250dd705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create our own website where we can enter the product name and its related data will be fetched from flipkart website through webscraping and later with the help of flask we will navigate to new page and display all the results that we got from webscraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd3280c6-bd7e-45bf-8a5f-5e81f9e2e01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12290756-44f3-44fc-9b85-872be787b82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Pipeline: It is used to connect our github repository and automate the deployment of software applications and manage the entire software release process. AWS Pipeline enables to build, test, and deploy code continuously\n",
    "# Elastic BeanStalk provides us the resources that is needed like ram , cpu , secodary memory. \n",
    "\n",
    "# github >> pipeline >> elastic beanstalk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bb6741-5479-430c-9f9b-09bae8e0b696",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
